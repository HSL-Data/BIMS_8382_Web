---
title: "Data Wrangling and Beyond"
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(warning = FALSE)
knitr::opts_chunk$set(message = FALSE)

```

# Data Wrangling and Cleaning

During today's class we are going to investigate trends in National Park visitors over the years. To do this we are going to need several/disparate datasets that are shaped and that look different from each other. We need to use functions from R to be able to join together these datasets and to  start to formulate hypotheses on what is going on in the National Parks.

# Set up

For today's lesson we will need packages in the tidyverse. Today we will be using the `dplyr`, `ggplot`, `readr`,  `stringr`, and `tidyr` packages, as well as the `openxlsx` package.

```{r}
# Load up the tidyverse
library(tidyverse)
# install.packages("openxlsx")
library(openxlsx)

```

# Read in data

We are going to use several datasets today. These datasets are not in our typical csv format. Two of them are found in the same excel file (`data.xlsx`) and the other dataset is in a .txt file (`pop.txt`).

We are first going to deal with the excel file by using the `read.xlsx` function from the `openxlsx` package. We first need to specify the name of the excel file and then the name of the sheet that the data comes from. Here the data file is simply called `data.xlsx` and the sheets are called `park_visits` and `gas_price`

```{r}
# Read in and save data using the read.xlsx function
park_visits <- read.xlsx("data.xlsx", sheet = "park_visits")
gas_price <- read.xlsx("data.xlsx", sheet = "gas_price")
```

The state population data is held in the `pop.txt` file that is delimited by tabs. You can read in delimited data using the `read_delim` function from the `readr` package. Since this data is delimited by a tab, we use the `\t` symbol. Our data could be delimited by any number of symbols or patterns (`,`, `.`, spaces, etc.). The `read_delim` function allows you flexibility to handle a number of different types of files.

```{r}
# The trim_ws option automatically trims away whitespace from the beginning and end of values.
state_pop <- read_delim("pop.txt", delim = "\t", trim_ws = TRUE)
```

Let's start by looking at our datasets using the `glimpse` function.

```{r}
#21,560 observations and 5 variables
#Uniquely identified by year and unit_name (Park name)
glimpse(park_visits)

#5916 observations and 3 variables 
#Uniquely identified by state and year
glimpse(state_pop)

#1 observation and 11 variables
#One row of data containing only the price of gas over several years
glimpse(gas_price)

```

We need to find a way to join together our three datasets. Our main dataset we are going to work with is the `park_visits` dataset. Since we want to join this dataset to our `state_pop` dataset, we need to make sure we have an identifier for state within our `park_visits` dataset. We currently do not have that identifier, but we do have something called `reg_state`. 

```{r}
#Let's look at the top of reg_state
head(park_visits$reg_state)
```

## `Separate()`
We can see a pattern here, where it starts with a two letter indicator for region followed by `:-:` and then a two letter abbreviation for state. We can use the `separate` function to separate out the region and the state based on the presense of the `:-:`

```{r}
#Separate takes in your dataset, the column you want to split or separate, the names you want to call your new columns (into = ), and the pattern that was separating the values (:-: in this case)
park_visits <- separate(park_visits, col = reg_state, into = c("region", "state"), sep = ":-:")
```

This separator could be a blank space, a number, a comma, or some random pattern of digits/punctuation marks/etc. This is where regular expressions would come in to play. Check out the regular expression cheat sheet to get some ideas on how they work.

https://rstudio.com/wp-content/uploads/2016/09/RegExCheatsheet.pdf

```{r}
# Here is a random example of a strange pattern that you could match using regular expressions. Here we have two letters, followed by 2 digits, followed by a blank space.
test <- tibble('test' = "test1YI83 test2")
test %>% 
  separate(col = test, into = c("col1", "col2"), sep = "[a-zA-Z]{2}[0-9]{2}[[:blank:]]{1}")

```

I want to also look a bit more at the `year` variable which I need to be numeric in order to join it together with the state population dataset. 

```{r}
# Let's look at the class of the year variable for both state_pop and park_visits
class(state_pop$year)
class(park_visits$year)

# Difficult to join together two datasets if you don't have matching variable types.

# Let's look at the different values for Year to see what is happening there.
park_visits %>% 
  distinct(year) %>% 
  arrange(year) %>% 
  tail(5)

# Why is "Total" there, let's take care of that. I am going to first filter out the "Total" value and then change it to a numeric variable
park_visits <- park_visits %>% 
  filter(year != "Total") %>% 
  mutate(year = as.numeric(year))

class(state_pop$year)
class(park_visits$year)

#So now we have a nice park_visits dataset with states and years in the format that we are looking for. 
```

## Catch Up

Here is the three files we are going to use moving forward. This is updated just in case you have any issues with the code above or were unable to read in from excel, etc.

```{r}

#gas_price <- read_csv("gas_price_p1.csv")
#state_pop <- read_csv("state_pop_p1.csv")
#park_visits <- read_csv("park_visits_p1.csv")

```

## Merging data Together

We have 3 datasets with the variables that we want. Our goal is to take our 3 datasets and create 1 dataset that we will work on moving forward. To do this, we are going to use a series of merges using  `join` functions. There are several types of `join` functions in R, all depending on your specific needs.

There are several types of joins (merges) that we can use. The one you use depends upon your specific needs.

The basic syntax for a join in dplyr:  
  
  `join(x, y, by = "")`
  
  `x = first dataset (left)`
  
  `y = second dataset (right)`
  
  `by = "unique identifer(s)"`
  
  
inner_join(): return all rows from x where there are matching values in y, and all columns from x and y. If there are multiple matches between x and y, all combination of the matches are returned.

left_join(): return all rows from x, and all columns from x and y. Rows in x with no match in y will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned.

right_join(): return all rows from y, and all columns from x and y. Rows in y with no match in x will have NA values in the new columns. If there are multiple matches between x and y, all combinations of the matches are returned.

full_join(): return all rows and all columns from both x and y. Where there are not matching values, returns NA for the one missing.

### Merging Examples

We are going to start by looking at some small examples of how these joins work.

```{r}
#We are going to look at different datasets with state, year, and different scores for...something.
# Run this code to create different tibbles/dataframes
df1 <- tibble(state = c("VA", "VA", "VA", "CA", "CA", "CA"),
           year = c(2003, 2004, 2005, 2003, 2004, 2005),
           score1 = c(42, 53, 12, 53, 96, 23))

df2 <- tibble(state = c("MD", "VA", "VA", "CA", "MD", "CA"),
      year = c(2003, 2004, 2008, 2003, 2004, 2005),
      score1 = c(95, 53, 91, 53, 34, 23),
      score2 = c('Low', 'High', 'Low', 'High', 'Low', 'High'))

df3 <- tibble(st = c("MD", "VA", "CA"),
              totalscore = c(13421, 234123, 5234))

score2 <- tibble(score2 = c('Low', 'High', 'Low', 'High', 'Low', 'High'))
```

For the following examples, the left dataset (x) is `df1`, the right dataset (y) is `df2`. 
The unique identifier between these two datasets are state and year. 
In this instance, you need to enter a vector (`c()`) for the unique identifier since it is more than one.

The first join we are going to do is a `left_join`, where we keep only the rows from df1 (x/left) dataset that have a match in the df2 (y/right) dataset.

```{r}
df1 %>% select(state, year)
df2 %>% select(state, year)

# How many observations do you think will be left after running the following merge?
left_join(df1, df2, by = c("state", "year"))
```

The `right_join` behaves in an opposite way to the left join, with only the rows from the right dataset being kept if it found a match in the left dataset.

```{r}
# How many observations?
right_join(df1, df2, by = c("state", "year"))
```

An `inner_join` only keeps those observations that have a match in both datasets. 
```{r}
# How many observations?
inner_join(df1, df2, by = c("state", "year"))
```

Finally, a `full_join` keep all observations from both datasets, even if there was no match. Tends to cause many `NA` values.

```{r}
#How many observations?
full_join(df1, df2, by = c("state", "year"))
```

In the case of unique identifiers that do not have the same name across datasets, you can match them up within the `by` argument.
```{r}
left_join(df1, df3, by = c("state" = "st"))
```

## Other ways to combine variables and cases

The `join` functions have some intelligence to their actions. However, you can use a couple of `bind` functions to simply add variables or cases to existing datasets.

Use `bind_cols()` to paste tables beside each other as they are. 
Use `bind_rows()` to paste tables below each other as they are.

```{r}
bind_cols(df1, score2)
bind_rows(df1, df2)
```

## Joining together our data

So now that we have seen how these merges work, let's go ahead and join together our `park_visits` and our `state_pop` datasets. 

```{r}
# If I want to keep only those observations that are in both datasets, what type of join should I use.
park_pop <- park_visits %>% 
  inner_join(state_pop, by = c("year", "state"))

glimpse(park_pop)
```

## Visualizing our new dataset

Let's visually look at this data using a new geom type, `geom_line`. The line graph works well on longitudinal/panel data. So we first need to get values for total visitors over the years.

```{r}
park_pop %>% 
  group_by(year) %>% 
  summarize(total_visits = sum(visitors)) %>% 
  ggplot(aes(year, total_visits)) + 
  geom_line()

park_pop %>% 
  group_by(year, region) %>% 
  summarize(total_visits = sum(visitors)) %>% 
  ggplot(aes(year, total_visits)) + 
  geom_line(aes(color = region))

park_pop %>% 
  group_by(year, region) %>% 
  summarize(total_visits = sum(visitors),
            population = sum(pop)) %>% 
  ggplot(aes(population, total_visits)) + 
  geom_line(aes(color = region))
```

## Reshaping your Data

Sometimes your data is not in a format that is conducive to properly joining together with another dataset. For instance, let's investigate the `gas_prices` dataset.

```{r}
gas_price
```

Notice that this is a wide dataset where we have multiple measures across the columns instead of having measures in observations. To be able to properly join this dataset to our `park_pop` dataset we need to change the format to long using the `pivot_longer` function.

`pivot_longer()` takes two important arguments:

`data, the dataframe to gather`

`cols, the columns to reshape`

```{r}
# Going from wide to long format
# Notice the `:` it essentially means to So this takes columns price_2006 to price_2015.
gas_price <- gas_price %>% 
  pivot_longer(cols = price_2006:price_2015)
gas_price
```

Notice that we now have a measure on each row. However, the data is still not exactly where we want it to be. Let us first use a very useful function called `str_replace` which is essentially a version of find and replace.

```{r}
#We also want to make the result of this numeric, since year is numeric in the park_pop dataset.
gas_price <- gas_price %>% 
  mutate(year = as.numeric(str_replace(name, "price_", "")))

#Notice here that we can rename variables within our select function.
gas_price <- gas_price %>% 
  select(year, gas_price = value)

#Let's finish this up by joining gas_price to park_pop and keeping all of the observations.
parks <- inner_join(park_pop, gas_price, by = "year")

```

`pivot_wider` takes a dataset from long to wide format. `pivot_wider` has three main arguments; 

`data, the dataframe to gather`

`names_from, the column that will provide the new names`

`values_from, the column that will provide the values`

```{r}
# Going from long to wide format
names(df1)
pivot_wider(df1, names_from = year, values_from = score1)
```

## Catch up two.

If you had any issues with the merge, use this to catch up to where we are.

```{r}
#parks <- read_csv("parks_merge.csv")
```

## Utilizing our new dataset.

We are now going to do some work on the `parks` dataset using both dplyr and ggplot. This will act as a bit of a refresher and as a way to introduce some concepts that might be useful for Tidy Tuesday. 

```{r}
# We can create a variable that compares values against the mean to see how each of the parks do against the average.
parks <- parks %>%
  group_by(year) %>% 
  mutate(vis_from_mean = visitors - mean(visitors, na.rm = TRUE))

# We can take this further by looking at which parks have the most visitors above the mean. 
parks %>% 
  group_by(region, state, unit_name) %>% 
  summarize(sum_vis_from_mean = sum(vis_from_mean, na.rm = TRUE), visitors = sum(visitors, na.rm = TRUE)) %>% 
  arrange(desc(sum_vis_from_mean)) %>% 
  head(12) %>% 
  select( region, state, unit_name, sum_vis_from_mean)

# Let's add in the idea of gas price and the number of visitors. Is their a relationship here?

p <- parks %>% 
  group_by(year) %>% 
  summarize(gas_price = mean(gas_price, na.rm = TRUE), visitors = sum(visitors, na.rm = TRUE)) %>% 
  ggplot(aes(x = gas_price, y = visitors)) + 
  geom_point() 
p 

# We can add a label to the plot, overwriting the point
p + geom_label(aes(label = year))

# We can also use the geom_text function to add text to the data.
p + geom_text(aes(label = year))

# May be a slight relationship between gas price and the number of visitors, but 2015 may be a bit of an abberation.

# Finally, let's look at visits over time with another line plot.
distinct(parks,year)

p <- parks %>% 
  group_by(year, region) %>% 
  summarize(total_visits = sum(visitors)) %>% 
  ggplot(aes(year, total_visits)) + 
  geom_line(aes(color = region))  
p

# Notice how the x axis looks quite strange and not all that useful. We can add our own version of the x axis using the scale_x_discrete and seq functions.
p +  scale_x_discrete(limits = c(seq(from = 2006, to = 2015, by = 1)))
```

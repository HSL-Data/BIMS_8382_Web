---
title: 'RNAseq Part 1: Rivanna'
author: "Katie Owsiany"
date: "2/10/2019"
output: html_document
---
[link back to the RNAseq lesson](https://bims8382.netlify.com/week7-rnaseq/rnaseq)

# RNAseq Part 1: Rivanna and Alignment
This workshop will provide a brief overveiw of the steps necessary to process RNAseq data from Illumina HighSeq reads, align these reads to a genome, and produce input files for DESeq2 analysis in R using Rivanna, UVA's high performance computing cluster.

## Introduction to Rivanna
Rivanna is a shared resource at UVA to allow students and researchers to perform computing tasks that are too large or complex to be done on a personal computer or laptop. A lab, PI, or department can request a free **allocation** of server space where data, code, and outputs can be stored.  This is also where you can access RNAseq data transferred to you from the UVA genomics core after your sequencing run. From your folder in Rivanna, you can submit high-performance computing **jobs** to be done on the system using the command **sbatch** (more on this later).

To get started on Rivanna and get an allocation, go to [this link](https://arcs.virginia.edu/allocations).  Also check out the [User Guide](https://arcs.virginia.edu/user-guide) to get started or make an appointment with the very friendly folks at Advanced Research Computing Services.

Your department or lab may already have such an allocation set up, in which case all you need is to request access for your netID from your system manager. 

## Logging in to Rivanna
Let's log in to Rivanna. From a mac, open **Terminal** and type

>ssh -Y YourNetIDhere@rivanna.hpc.virginia.edu

Allow registration of the RSA host key for Rivanna by typing `yes`.
When prompted put in your NetID password. If successful you will see 

>***Welcome to Rivanna***
-bash-4.2$



#Workflow
The workflow for an RNAseq experiment will follow these basic steps: 

1. **Set up variables and folders**
2. **Chastity filter** *make sure all files are in the right format*
3. **FastQC** *check quality of reads*
4. **STAR Alignment** *align the reads to the genome*
5. **FeatureCounts** *count the reads aligning to each gene*

## 1. Set up variables and folders
First we're going to make all the folders in /scratch to serve as input and output for our analysis. Quick tutorial on bash commands: 

- **cd**  *change directory*
- **mkdir**  *make directory*
- **./** *folder you are currently in* 
- **~/** *home folder*
- **up arrow** *last typed command*
- **down arrow** *next typed command*
- **tab** *complete line w/out typing, suggestions for your options*
- **pwd** *print working directory, aka "where am I?"*
- **ls** *list current subfolders*
- **man** *manual, look up help files*

We will make folders for each of the steps in our analysis in the [RNAseq] folder. 

>bash-4.2$ cd ./[RNAseq]

>bash-4.2$ mkdir [filter]

>bash-4.2$ mkdir [scripts]

>bash-4.2$ mkdir [alndir]

Check that all your folders are made by typing 

> bash-4.2$ ls

You should see 

> bash-4.2$ [alndir] [data] [filter] [scripts]

Great. Now we will make variables. These are important so that you can run the same scripts on multiple experiments or at multiple locations or points in time, changing only the variables or paths and not re-writing the whole script. In bash a variable looks like this: 

>$VARIABLE

And it can be set to any value by altering its path in the ***home environment***. This is found by going to your home directory 

>bash-4.2$ cd /home/ko8xh

and entering the text editor for your ***home environment***. This is basically a document that tells Rivanna what your baseline settings are, kind of like the user account when you log into a computer. 

>bash-4.2$ nano .bashrc

The basic format to make a variable is "export VARIABLE=/path". Copy and paste the following variables into your environment
```
export DATADIR=/scratch/ko8xh/[RNAseq]/[data]
export FILTDIR=/scratch/ko8xh/[RNAseq]/[filter]
export ALNDIR=/scratch/ko8xh/[RNAseq]/[alndir]
export GENOMEDIR=/nv/vol101/Owens_Lab/genomes/gencode-m16
export ANNOTATION=/nv/vol101/Owens_Lab/genomes/gencode-m16/gencode.vM16.chr_pat$
export STAR=/sfs/nfs/blue/gf8kz/bin/STAR
export FCOUNTS=/sfs/nfs/blue/gf8kz/bin/featureCounts
export EXPERIMENT=RNAseq
export SCRIPTS=/scratch/ko8xh/[RNAseq]/[scripts]
```

Then save this document by typing **command O** and exit the text editor by typing **command X**. 

That's a lot of variables!  But remember, the variable is just a path to a file of your choice. For example, if we want to go to the scripts folder, now that we set the variable SCRIPTS, we can simply type 

>bash-4.2$ cd $SCRIPTS

Instead of 

>bash-4.2$ cd /scratch/ko8xh/[RNAseq]/[scripts]

Similarly, if we want to write a script that will perform a command on each of our data files in our [data] folder, we can now use $DATADIR to call that location in the script instead of typing out /scratch/ko8xh/[RNAseq]/[data]. If you want to use this workflow to analyze a new data set in the future, now all you have to do is change the path of these variables to lead to folders where you put your new data. 

Importantly, in Rivanna and bash script, unlike in R, there is no place to record exactly what code you ran in what environment. Thus, it is important to save a copy of what you ran and what your variables were set to by making an R markdown document.

Ok, now that we have set up our environment, we are ready to get our data. 
If you do sequencing at the UVA genomics core, you can request that your data is placed in your folder on Rivanna in .fastq format. Today we will use my data from an experiment where I sorted different subsets of smooth muscle cells from a site of injury in our mouse model, and compared their transcriptomes by RNAseq. Let's check out this data in $DATADIR

>bash-4.2$ cd $DATADIR

>bash-4.2$ ls
```
DoublePosAth_S4_L001_R1_001.fastq.gz  Greenburn_S1_L004_R2_001.fastq.gz
DoublePosAth_S4_L001_R2_001.fastq.gz  TomB_S3_L001_R1_001.fastq.gz
DoublePosAth_S4_L002_R1_001.fastq.gz  TomB_S3_L001_R2_001.fastq.gz
DoublePosAth_S4_L002_R2_001.fastq.gz  TomB_S3_L002_R1_001.fastq.gz
DoublePosAth_S4_L003_R1_001.fastq.gz  TomB_S3_L002_R2_001.fastq.gz
DoublePosAth_S4_L003_R2_001.fastq.gz  TomB_S3_L003_R1_001.fastq.gz
DoublePosAth_S4_L004_R1_001.fastq.gz  TomB_S3_L003_R2_001.fastq.gz
DoublePosAth_S4_L004_R2_001.fastq.gz  TomB_S3_L004_R1_001.fastq.gz
GreenAth_S5_L001_R1_001.fastq.gz      TomB_S3_L004_R2_001.fastq.gz
GreenAth_S5_L001_R2_001.fastq.gz      TomUB_S2_L001_R1_001.fastq.gz
GreenAth_S5_L002_R1_001.fastq.gz      TomUB_S2_L001_R2_001.fastq.gz
GreenAth_S5_L002_R2_001.fastq.gz      TomUB_S2_L002_R1_001.fastq.gz
GreenAth_S5_L003_R1_001.fastq.gz      TomUB_S2_L002_R2_001.fastq.gz
GreenAth_S5_L003_R2_001.fastq.gz      TomUB_S2_L003_R1_001.fastq.gz
GreenAth_S5_L004_R1_001.fastq.gz      TomUB_S2_L003_R2_001.fastq.gz
GreenAth_S5_L004_R2_001.fastq.gz      TomUB_S2_L004_R1_001.fastq.gz
Greenburn_S1_L001_R1_001.fastq.gz     TomUB_S2_L004_R2_001.fastq.gz
Greenburn_S1_L001_R2_001.fastq.gz     U552KO1963_01
Greenburn_S1_L002_R1_001.fastq.gz     U552KO1963_02
Greenburn_S1_L002_R2_001.fastq.gz     U552KO1963_03
Greenburn_S1_L003_R1_001.fastq.gz     U552KO1963_04
Greenburn_S1_L003_R2_001.fastq.gz     U552KO1963_05
Greenburn_S1_L004_R1_001.fastq.gz
```

These files are set up based on the sample, lane, and read of the sequencing machine on which they were read. Each sample submitted by me has a different name, followed by the sample number it was assigned for sequencing, the lane and paired-end read identity recorded by the sequencing machine. It goes "samplename_Samplenumber_lane_read_001.fastq.gz" These names are important for the way the scripts are written- often, a script will call part of a name, such as "*.fastq.gz" meaning "all files ending with fastq.gz", or will chop off part of a name so that all the samples go through a process, then tack it back on at the end. If there are errors in your script it is very likely they are related to an inconsistency or error in these file names; similarly, to use these scripts with data that is not named in this way, adaptation will be necessary. For now, we will use this format that is the output of the UVA genomics core facility. 

To get your data from a UVA core facility folder in Rivanna, go to that folder and use command ***rsync*** to copy and paste data into your folder. For example, to get my data, I navigated to the folder with my data specified by the genome core and typed 

>bash-4.2$ rsync -t *fastq.gz /scratch/ko8xh/[RNAseq]/[data]

This will transfer all files ending with fastq.gz to my [data] folder.

If you get data from outside UVA that you want to upload to your folder in Rivanna, download and install the [Globus](https://app.globus.org/file-manager) file transfer tool to drag and drop files from your computer or a specified server into Rivanna. 

If you want to load all the scripts ahead of time, instead of creating each one in Rivanna, use Globus to import the scripts.zip file into your $SCRIPTS folder. Each of these scripts will also be spelled out in later steps as we go along.

Ok, now that we have our data, it's time to execute our first job. 

## 2. Chastity Filter
This step makes sure all of the .fastq.gz files are in the right format. Check out the fastq format and what it means [here](https://en.wikipedia.org/wiki/FASTQ_format). 

Each of our scripts will contain headers with information for Rivanna about how many nodes to use, how many tasks there will be, how much memory should be used, and how much time it will take. It also indicates what account should be charged for the job. For the most part, you can use the fields provided as a guideline- mostly these values are to stop scripts that are running in loops after say, 20 minutes, stop scripts with mistakes that would take up excessive memory on Rivanna, etc. The last field should be edited after -A **to indicate your rivanna account for payment**. Each job on Rivanna charges a small fee related to how much computing power was needed to complete it. More details on Rivanna's fee structure and paramters for submitting jobs can be found [here](https://arcs.virginia.edu/getting-started#toc-14)

Let's take a look at the chastity-filter-slurm.sh script: 
```
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=2400
#SBATCH --time=800
#SBATCH -p standar 
#SBATCH -A owens_rivanna

#DATADIR=/scratch/ko8xh/[RNAseq]/[data]
#FILTDIR=/scratch/ko8xh/[RNAseq]/[filter]

DATADIR=${DATADIR}
FILTDIR=${FILTDIR}

find $DATADIR -name "*.fastq.gz" | sed 's/.fastq.gz//g' | awk -F"/" '{print $NF}' | sort | parallel -j 1 "zcat $DATADIR/{}.fastq.gz | grep -A 3 '^@.*[^:]*:N:[^:]*:' | grep -v '^\-\-$' | gzip -c > $FILTDIR/{}.fq.gz"
```
Basically, all of the commented lines (denoted by #) are communicating with Rivanna about the job and reminding us what our variables $DATADIR and $FILTDIR are set to. The last line is the code, which is saying, in the folder $DATADIR, find all the files ending with .fastq.gz, remove everything except their base file name, select the first feild of that name (which is "Greenath" or my sample name). Open up this file, find things that start with an @ and contain an **N** at a specific position. This position is the Illumina quality control step that the signal intensity for that base call is coming from a single cluster (N, passing) or multiple clusters (Y, does not pass).  Then print all these sequences into $FILTDIR.  

This script makes sure that all sequence reads we will analyze passed Illumina's internal quality control and moves those reads into the [filter] folder.

To run this script, we will do our first job submission on Rivanna. First, make sure you are in your [scripts] folder. To insert the above text into a script named "chastity-filter-slurm.sh" Type 

>bash-4.2$ nano chastity-filter-slurm.sh

This will open the text editor in your [scripts] folder and create a document named "chastity-filter-slurm.sh" Paste the above code into this document, save using **command O** and exit using **command X**. Then, to submit the job to Rivanna, stay in your [scripts] folder and type 

>bash-4.2$ sbatch chastity-filter-slurm.sh

That's it! You've submitted a job to Rivanna. To check if your job is running, type 

>bash-4.2$ squeue -u ko8xh

Importantly, note your JOBID number. This number will be associated with a file in [scripts] after the job has finished giving any error messages about your run. To read this message, type 

>bash-4.2$ more slurm-JOBID.out

If your job completed successfully, you will see files appear in your [filter] folder. Check this out by typing 

>bash-4.2$ cd $FILTDIR

>bash-4.2$ ls

You should see a list of your files, now ending with .fq.gz. 

##3. FastQC
On to Fast QC! This is a program that does additional quality control of your data files and generates .html summaries of each file's quality. Like R, Rivanna has a number of **modules** (aka packages) available for common biomedical research tasks. FastQC is one of these modules and all we have to do is load it, run it, and look at the output. 

>bash-4.2$ cd $SCRIPTS

>bash-4.2$ nano FastQC-slurm.sh

Script: 

```
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=10gb
#SBATCH --time=300
#SBATCH -p standard
#SBATCH -A owens_rivanna

FILTDIR=$FILTDIR

cd $FILTDIR

module load fastqc
find $FILTDIR -name "*.gz" | xargs -i fastqc {}
```
The results files will be .html in the folder $FILTDIR (you can also move these files to their own folder named fastqc_trimmed) and you can transfer these to your computer using [Globus](https://app.globus.org/file-manager) and open them in any web browser. For information about reading your FastQC files and what the parameters mean, check out [this link](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/).
Navigate to $SCRIPTS and submit this script as a batch job. 

>bash-4.2$ cd $SCRIPTS
>bash-4.2$ sbatch FastQC-slurm.sh

##3. STAR Alignment
Once we are sure that our sequences are of good quality, we can move on to alignment. We will use the STAR program of alignment- I highly recommend reading this [manual](https://github.com/alexdobin/STAR/blob/master/doc/STARmanual.pdf) for more information about the parameters used to run this analysis. Alignment is one of the steps most likely to influence the meaning of your downstream results, and there are a lot of different ways to do it that take into account different experimental parameters. 

The number one thing that you may want to change in your analyses is the genome reference used in $GENOMEDIR. Otherwise the STAR module can be downloaded into your own folder. 

A brief overview of the parameters we are using today, with a special shoutout to Dr. Gabe Alencar, PhD, who proposed these: 

1. Encode:
- **outFilterType** BySJout -> reduces the number of spurious junctions. Keep only those reads that contain junctions that passed filtering into SJ.out.tab. Default: Normal
- **outFilterMultimapNmax** 20 -> maximum number of loci the read is allowed to map. Alignments (all of them) will be output only if the read maps to no more loci that this value. Default: 10
- **alignSJoverhangMin** 8 -> minimum overhang (i.e. block size) for spliced alignments. This is for unannotated junctions. Default: 5
- **alignSJDBoverhangMin** 1 -> minimum overhang (i.e. block size) for annotated (sjdb) spliced alignments. This is for annotated junctions. Default: 0
- **outFilterMismatchNmax** 999 -> maximum number of mismatches per pair. A large number will switch off this filter. Default: 10
- **outFilterMismatchNoverReadLmax** 0.04 -> max number of mismatches per pair relative to read length: i.e. for 2x100b (as our experiment), max number of mismatches is 0.04 x 200 = 8 for the paired read. Default: 1.0
- **alignIntronMin** 20 -> minimun intron length. A genomic gap is considered intron if its length >=alignIntronMin, otherwise it is considered Deletion. Default: 21
- **alignIntronMax** 1000000 -> maximum intron length. If 0, it will use a formula based on other parameters to define max intron size. Default: 0.
- **alignMatesGapMax** 1000000 -> maximun genomic distance between mates. If 0, max intron gap will be determine by the same formula used in alignIntronMax. Default: 0

2. General Purpose/StringTie:
- **runThreadN** 8
- **genomeDir**
- **readFilesCommand** zcat
- **readFilesIn**
- **outFileNamePrefix** {name}.2.star
- **outSAMtype** BAM SortedByCoordinate
- **limitBAMsortRAM** 50000000000
- **outSAMstrandField** intronMotif
- **twopassMode** Basic
- **outWigType** bedGraph

These parameters can be altered in the script below to your liking. 

>bash-4.2$ cd $SCRIPTS

>bash-4.2$ nano STAR-slurm.sh

Script: 
```
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=240gb
#SBATCH --time=800
#SBATCH -p standard
#SBATCH -A owens_rivanna

ALNDIR=$ALNDIR
FILTDIR=$FILTDIR
GENOMEDIR=$GENOMEDIR
STAR=$STAR
ANNOTATION=$ANNOTATION
DoublePosAth_S4_L001_R1_001.fastq.gz 
find $FILTDIR -name "*.gz"| awk -F"/" '{print $NF}' | cut -f 1-3 -d "_" | sort -u | parallel -j 1 "$STAR --readFilesCommand zcat --runThreadN 12 --genomeDir $GENOMEDIR  --readFilesIn $FILTDIR/{}_R1_001.fq.gz $FILTDIR/{}_R2_001.fq.gz --outFileNamePrefix $ALNDIR/{}.star. --outSAMtype BAM SortedByCoordinate --limitBAMsortRAM 500000000000 --outSAMstrandField intronMotif --outFilterType BySJout --outFilterMultimapNmax 20 -- alignSJoverhangMin 8 --alignSJDBoverhangMin 1 --outFilterMismatchNmax 999 --outFilterMismatchNoverLmax 0.04 --alignIntronMin 20 --alignIntronMax 1000000 --alignMatesGapMax 1000000 --twopassMode Basic --outWigType bedGraph"
```
Importantly, this script is reading our files from FILTDIR, both of the paired reads specified by  _R1_001.fq.gz and _R2_001 .fq.gz. You can alter the name of the output file after "--outFileNamePrefix". Here it is "$ALNDIR/{}.star".

Let's run this script. Alignment is usually the longest step computationally and may run overnight.

>bash-4.2$ cd $SCRIPTS

>bash-4.2$ sbatch STAR-slurm.sh

Check the version number for publication: 

>bash-4.2$ $STAR --version

##5. Feature Counts
Now that all the reads are aligned, we want to count up how many reads were assigned to the same feature in each sample. This is a module called featureCounts, and it assigns these reads to a feature provided in the genome annotation located in the variable $ANNOTATION. 


Script: 
```
#!/bin/bash
#SBATCH --nodes=1
#SBATCH --ntasks=20
#SBATCH --mem=240gb
#SBATCH --time=800
#SBATCH -p standard
#SBATCH -A owens_rivanna

ANNOTATION=$ANNOTATION
ALNDIR=$ALNDIR
EXPERIMENT=$EXPERIMENT
FCOUNTS=$FCOUNTS

featureCounts -a $ANNOTATION -o $ALNDIR/$EXPERIMENT.counts.txt -p -B -T 12 -t exon -g gene_id $ALNDIR/Greenburn_S1_L001.star.Aligned.sortedByCoord.out.bam $ALNDIR/Greenburn_S1_L002.star.Aligned.sortedByCoord.out.bam $ALNDIR/Greenburn_S1_L003.star.Aligned.sortedByCoord.out.bam $ALNDIR/Greenburn_S1_L004.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomB_S3_L001.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomB_S3_L002.2.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomB_S3_L003.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomB_S3_L004.2.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomUB_S2_L001.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomUB_S2_L002.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomUB_S2_L003.star.Aligned.sortedByCoord.out.bam $ALNDIR/TomUB_S2_L004.star.Aligned.sortedByCoord.out.bam
```

>bash-4.2$ cd $SCRIPTS

>bash-4.2$ sbatch Featurecounts-slurm.sh

The output of this is a file called $EXPERIMENT.counts.txt. This is your "count matrix" that we will input into DESeq2.